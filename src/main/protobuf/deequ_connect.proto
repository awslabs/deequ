/**
 * Copyright 2024 Amazon.com, Inc. or its affiliates. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"). You may not
 * use this file except in compliance with the License. A copy of the License
 * is located at
 *
 *     http://aws.amazon.com/apache2.0/
 *
 * or in the "license" file accompanying this file. This file is distributed on
 * an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either
 * express or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */

syntax = "proto3";

package com.amazon.deequ.connect;

option java_multiple_files = true;
option java_package = "com.amazon.deequ.connect.proto";
option java_outer_classname = "DeequConnectProtos";

// ============================================================================
// Main Request Messages - Used as Spark Connect Relation Extensions
// ============================================================================

// Verification request - runs checks and returns results as DataFrame
message DeequVerificationRelation {
  // Reference to the input DataFrame (serialized Spark Connect Relation)
  bytes input_relation = 1;

  // Checks to run
  repeated CheckMessage checks = 2;

  // Additional analyzers to run (beyond those required by checks)
  repeated AnalyzerMessage required_analyzers = 3;
}

// Analysis request - runs analyzers and returns metrics as DataFrame
message DeequAnalysisRelation {
  // Reference to the input DataFrame
  bytes input_relation = 1;

  // Analyzers to run
  repeated AnalyzerMessage analyzers = 2;
}

// ============================================================================
// Check Messages
// ============================================================================

// Check definition - a named collection of constraints
message CheckMessage {
  // Check severity level
  enum Level {
    ERROR = 0;
    WARNING = 1;
  }

  Level level = 1;
  string description = 2;
  repeated ConstraintMessage constraints = 3;
}

// ============================================================================
// Constraint Messages
// ============================================================================

// Constraint definition - a single data quality rule
message ConstraintMessage {
  // Constraint type identifier
  string type = 1;

  // Common fields
  string column = 2;                    // Single column name
  repeated string columns = 3;          // Multiple column names
  PredicateMessage assertion = 4;       // Assertion predicate
  string hint = 5;                      // Hint message for failures
  string where = 6;                     // SQL WHERE clause filter

  // Type-specific fields
  string pattern = 7;                   // Regex pattern (for hasPattern, containsEmail, etc.)
  string column_condition = 8;          // SQL condition (for satisfies)
  string constraint_name = 9;           // Name for custom constraints (for satisfies)
  repeated string allowed_values = 10;  // Allowed values (for isContainedIn)

  // Numeric parameters
  double quantile = 11;                 // For hasApproxQuantile
}

// ============================================================================
// Predicate Messages - Replaces Python Lambda Assertions
// ============================================================================

// Predicate for numeric assertions
message PredicateMessage {
  enum Operator {
    UNSPECIFIED = 0;  // Default/unset - used to detect "no predicate" vs "EQ 0.0"
    EQ = 1;           // ==
    NE = 2;           // !=
    GT = 3;           // >
    GE = 4;           // >=
    LT = 5;           // <
    LE = 6;           // <=
    BETWEEN = 7;      // lower <= x <= upper
  }

  Operator operator = 1;
  double value = 2;           // For comparison operators
  double lower_bound = 3;     // For BETWEEN
  double upper_bound = 4;     // For BETWEEN
}

// ============================================================================
// Analyzer Messages
// ============================================================================

// Analyzer definition - computes a metric on data
message AnalyzerMessage {
  // Analyzer type identifier
  string type = 1;

  // Common fields
  string column = 2;              // Single column name
  repeated string columns = 3;    // Multiple column names
  string where = 4;               // SQL WHERE clause filter

  // Type-specific parameters
  double quantile = 5;            // For ApproxQuantile
  double relative_error = 6;      // For ApproxQuantile, ApproxCountDistinct
  string pattern = 7;             // For PatternMatch
  int32 max_detail_bins = 8;      // For Histogram

  // KLL Sketch parameters
  KLLParameters kll_parameters = 9;
}

// Parameters for KLL Sketch analyzer
message KLLParameters {
  int32 sketch_size = 1;
  double shrinking_factor = 2;
  int32 number_of_buckets = 3;
}

// ============================================================================
// Result Messages
// ============================================================================

// Verification result status
enum VerificationStatus {
  VERIFICATION_SUCCESS = 0;
  VERIFICATION_WARNING = 1;
  VERIFICATION_ERROR = 2;
}

// Check result status
enum CheckStatus {
  CHECK_SUCCESS = 0;
  CHECK_WARNING = 1;
  CHECK_ERROR = 2;
}

// Constraint result status
enum ConstraintStatus {
  CONSTRAINT_SUCCESS = 0;
  CONSTRAINT_FAILURE = 1;
}

// Metric entity type
enum MetricEntity {
  DATASET = 0;
  COLUMN = 1;
  MULTICOLUMN = 2;
}

// ============================================================================
// Column Profiler Messages
// ============================================================================

// Column profiler request - analyzes column distributions and statistics
message DeequColumnProfilerRelation {
  // Reference to the input DataFrame (serialized Spark Connect Relation)
  bytes input_relation = 1;

  // Restrict profiling to specific columns (empty = all columns)
  repeated string restrict_to_columns = 2;

  // Threshold for computing histograms (columns with distinct values <= threshold get histograms)
  int32 low_cardinality_histogram_threshold = 3;

  // Enable KLL sketch profiling for approximate quantiles
  bool enable_kll_profiling = 4;

  // KLL sketch parameters (only used if enable_kll_profiling is true)
  KLLParameters kll_parameters = 5;

  // Predefined data types for columns (column_name -> type_name)
  // Supported types: "String", "Integer", "Long", "Double", "Boolean"
  map<string, string> predefined_types = 6;
}

// ============================================================================
// Constraint Suggestion Messages
// ============================================================================

// Constraint suggestion request - auto-generates data quality rules
message DeequConstraintSuggestionRelation {
  // Reference to the input DataFrame (serialized Spark Connect Relation)
  bytes input_relation = 1;

  // Constraint rule sets to apply
  // Values: "DEFAULT", "STRING", "NUMERICAL", "COMMON", "EXTENDED"
  repeated string constraint_rules = 2;

  // Restrict suggestions to specific columns (empty = all columns)
  repeated string restrict_to_columns = 3;

  // Threshold for computing histograms
  int32 low_cardinality_histogram_threshold = 4;

  // Enable KLL sketch profiling
  bool enable_kll_profiling = 5;

  // KLL sketch parameters
  KLLParameters kll_parameters = 6;

  // Predefined data types for columns
  map<string, string> predefined_types = 7;

  // Train/test split ratio (0.0 = disabled, 0.0-1.0 = ratio for test set)
  double testset_ratio = 8;

  // Random seed for train/test split (0 = no seed)
  int64 testset_split_random_seed = 9;
}
