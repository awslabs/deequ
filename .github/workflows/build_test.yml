name: BuildAndTest

on:
  push:
    branches:
      - master
      - '!release*'
  pull_request:
    branches:
      - master
      - '!release*'
jobs:
  build:
    name: "Build Deequ with JDK ${{ matrix.java }}, Hadoop ${{ matrix.hadoop }}, Spark ${{ matrix.spark-version }}"
    # os: [ubuntu-latest, macos-latest, windows-latest]
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: false
      matrix:
        include:
          - java: 8
            hadoop: 2.7
            spark-version: 2.4.7
            python-version: 3.6
          - java: 8
            hadoop: 3.2
            spark-version: 3.0.2
            python-version: 3.6
          - java: 11
            hadoop: 3.2
            spark-version: 3.0.2
            python-version: 3.6
          - java: 8
            hadoop: 2.7
            spark-version: 3.0.2
            python-version: 3.6
          - java: 11
            hadoop: 2.7
            spark-version: 3.0.2
            python-version: 3.6
          - java: 8
            hadoop: 3.2
            spark-version: 3.1.1
            python-version: 3.6
          - java: 11
            hadoop: 3.2
            spark-version: 3.1.1
            python-version: 3.6
          - java: 8
            hadoop: 2.7
            spark-version: 3.1.1
            python-version: 3.6
          - java: 11
            hadoop: 2.7
            spark-version: 3.1.1
            python-version: 3.6
    env:
      GITHUB_PREV_SHA: ${{ github.event.before }}
      PYTHON_VERSION: ${{ matrix.python-version }}
      SPARK_VERSION: ${{ matrix.spark-version }}
    timeout-minutes: 60
    steps:
      - name: Checkout Spark repository
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set up JDK
        uses: actions/setup-java@v2
        with:
          java-version: ${{ matrix.java }}
          distribution: 'adopt'

      - name: Run setup-spark ${{ matrix.spark-version }}
        uses: vemonet/setup-spark@v1
        with:
          spark-version: ${{ matrix.spark-version }}
          hadoop-version: ${{ matrix.hadoop }}

      - name: Check Java
        run: java -version

      - name: Check Spark
        run: spark-submit --version

      - name: Check Disk Size before Cache
        run: |
          df -hm

      - name: Cache Maven packages
        uses: actions/cache@v2
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - name: Check Maven-com Cache
        uses: actions/cache@v2
        with:
          path: ~/.m2/repository/com
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: |
            ${{ runner.os }}-m2-

      - name: Check Disk Size before Build
        run: |
          df -hm

      - name: Build with Maven
        run: mvn clean install

      - name: Check Disk Size after Build
        run: |
          df -hm
      #   run: mvn --batch-mode --update-snapshots verify

      # - run: mkdir staging && cp target/*.jar staging
      # - uses: actions/upload-artifact@v2
      #   with:
      #     name: Package
      #     path: staging
